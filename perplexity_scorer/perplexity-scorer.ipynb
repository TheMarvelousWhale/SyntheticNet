{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "34b86069-44b7-4e6c-81be-c47da4d4eeaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset wikitext (C:\\Users\\hoang\\.cache\\huggingface\\datasets\\wikitext\\wikitext-2-raw-v1\\1.0.0\\aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20)\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 90.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average perplexity is: 1.0010002851486206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForMaskedLM, AutoTokenizer\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from datasets import load_dataset\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "model_id = 'roberta-base'\n",
    "model = AutoModelForMaskedLM.from_pretrained(model_id).to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "test_sentences = []  #replace this with your list of sentence\n",
    "\n",
    "if test_sentences == []:\n",
    "    test_sentences = load_dataset('wikitext', 'wikitext-2-raw-v1', split='test')['text'][:1]\n",
    "    \n",
    "encodings = tokenizer('\\n\\n'.join(test_sentences), return_tensors='pt')\n",
    "\n",
    "max_length = 512\n",
    "stride = 512\n",
    "\n",
    "lls = []\n",
    "for i in tqdm(range(0, encodings.input_ids.size(1), stride)):\n",
    "    begin_loc = max(i + stride - max_length, 0)\n",
    "    end_loc = min(i + stride, encodings.input_ids.size(1))\n",
    "    trg_len = end_loc - i    # may be different from stride on last loop\n",
    "    input_ids = encodings.input_ids[:,begin_loc:end_loc].to(device)\n",
    "    target_ids = input_ids.clone()\n",
    "    target_ids[:,:-trg_len] = -100   #invalidate the context tokens\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids, labels=target_ids)\n",
    "        log_likelihood = outputs[0] * trg_len\n",
    "\n",
    "    lls.append(log_likelihood)\n",
    "\n",
    "ppl = torch.exp(torch.stack(lls).sum() / end_loc)\n",
    "print(f\"The average perplexity is: {ppl}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4aa5e213-fd0b-47d6-9ff6-0f352a077ee8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4248a597-9773-43a6-b3c3-840c7c2cac01",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
