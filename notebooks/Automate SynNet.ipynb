{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3d2a907-65e8-4518-8615-819bfd89037d",
   "metadata": {},
   "source": [
    "Standardize for each experiment:\n",
    "* What data is it run on\n",
    "* What are the loss objective and metrics (cosine sim)\n",
    "* Running epoch and results \n",
    "* Versioning of data and model (offline, use wandb-id)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4511203d-a5b5-4aa7-b0d6-87f3174c0e97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Sample: \n",
    "        config.data = \"wiki_data, word cats and pneumonia\"\n",
    "        config.loss = \"L1\"\n",
    "        config.simscore = \"\"\n",
    "        config.batch_size\n",
    "        config.epoch\n",
    "        config.lr\n",
    "        config.momentum (since we are using SGD)\n",
    "\"\"\"\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46977efd-dfac-4407-b5cf-b74e718bb227",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import wandb\n",
    "import re\n",
    "import random\n",
    "from datetime import date\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9eda3fba-3bb8-4490-8f38-5909d525ab2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class DenseNet(nn.Module):\n",
    "    def __init__(self,context_length,embed_size=100):\n",
    "        super().__init__()\n",
    "        self.n = context_length*2\n",
    "        self.embed_size = 100\n",
    "        self.act = nn.ReLU()\n",
    "        self.out = nn.Tanh() \n",
    "        self.hidden1 = nn.Linear(self.n*self.embed_size,2048)\n",
    "        self.hidden2 = nn.Linear(2048,512)\n",
    "        self.hidden3 = nn.Linear(512,self.embed_size)\n",
    " \n",
    "    def forward(self,x):\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.act(self.hidden1(x))\n",
    "        x = self.act(self.hidden2(x))\n",
    "        x = self.out(self.hidden3(x))\n",
    "        return x\n",
    "    \n",
    "    \n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5149ce5e-c6a3-40f1-9bed-078129dd8e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from util import *\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6900d90c-7755-4537-a800-160bfa479ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import random\n",
    "#Loading the data\n",
    "W_norm,vocab,ivocab = load_glove()\n",
    "    \n",
    "def negative_sample(samples,target,num=4):\n",
    "    negative_samples = [x  for x in samples if x != target]\n",
    "    return [target] + random.sample(samples,num)\n",
    "\n",
    "raw_word_list = ['location','position','site','land','place','city','district','area','leader','president','governor','mentor','director','command',\n",
    "                'authority','influence','teacher','cat','dog','whale','computer','shark','university','class','speak','cute']\n",
    "\n",
    "chosen_words = ['disease' for _ in range(5)]\n",
    "word_lists = [negative_sample(raw_word_list,w,4) for w in chosen_words]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93f02739-c4d4-4fe7-add7-a09a80fa5730",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['disease', 'president', 'teacher', 'land', 'shark'],\n",
       " ['disease', 'area', 'class', 'governor', 'place'],\n",
       " ['disease', 'teacher', 'location', 'position', 'speak'],\n",
       " ['disease', 'director', 'position', 'district', 'computer'],\n",
       " ['disease', 'command', 'area', 'position', 'district']]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794c36e8-5c37-4767-aa61-f015017f61b7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:11sxslgc) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 6392<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>C:\\Users\\hoang\\Desktop\\Light\\Torch_playground\\FYPv2\\notebooks\\wandb\\run-20210905_144329-11sxslgc\\logs\\debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>C:\\Users\\hoang\\Desktop\\Light\\Torch_playground\\FYPv2\\notebooks\\wandb\\run-20210905_144329-11sxslgc\\logs\\debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">vibrant-elevator-34</strong>: <a href=\"https://wandb.ai/sosig_catto/Synthetic%20Net/runs/11sxslgc\" target=\"_blank\">https://wandb.ai/sosig_catto/Synthetic%20Net/runs/11sxslgc</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "...Successfully finished last run (ID:11sxslgc). Initializing new run:<br/><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: wandb version 0.12.1 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.30<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">lucky-shape-35</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/sosig_catto/Synthetic%20Net\" target=\"_blank\">https://wandb.ai/sosig_catto/Synthetic%20Net</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/sosig_catto/Synthetic%20Net/runs/2ti4vrm6\" target=\"_blank\">https://wandb.ai/sosig_catto/Synthetic%20Net/runs/2ti4vrm6</a><br/>\n",
       "                Run data is saved locally in <code>C:\\Users\\hoang\\Desktop\\Light\\Torch_playground\\FYPv2\\notebooks\\wandb\\run-20210905_144416-2ti4vrm6</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|██                                                                              | 1/40 [08:21<5:25:44, 501.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:01\t|\tTrain Loss: 1468.736\t|\tCosim score: 0.823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|████                                                                            | 2/40 [16:40<5:16:50, 500.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:02\t|\tTrain Loss: 1241.317\t|\tCosim score: 0.853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|██████                                                                          | 3/40 [25:03<5:09:13, 501.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:03\t|\tTrain Loss: 1205.325\t|\tCosim score: 0.857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████████                                                                        | 4/40 [33:34<5:02:59, 504.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:04\t|\tTrain Loss: 1191.590\t|\tCosim score: 0.857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|██████████                                                                      | 5/40 [42:06<4:56:02, 507.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:05\t|\tTrain Loss: 1184.229\t|\tCosim score: 0.856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|████████████                                                                    | 6/40 [50:37<4:48:21, 508.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:06\t|\tTrain Loss: 1179.821\t|\tCosim score: 0.856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|██████████████                                                                  | 7/40 [59:07<4:40:06, 509.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:07\t|\tTrain Loss: 1177.130\t|\tCosim score: 0.855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|███████████████▌                                                              | 8/40 [1:07:37<4:31:45, 509.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:08\t|\tTrain Loss: 1175.505\t|\tCosim score: 0.855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|█████████████████▌                                                            | 9/40 [1:16:06<4:23:11, 509.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:09\t|\tTrain Loss: 1174.523\t|\tCosim score: 0.855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|███████████████████▎                                                         | 10/40 [1:24:54<4:17:28, 514.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10\t|\tTrain Loss: 1173.938\t|\tCosim score: 0.854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|█████████████████████▏                                                       | 11/40 [1:34:33<4:18:21, 534.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:11\t|\tTrain Loss: 1173.608\t|\tCosim score: 0.854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███████████████████████                                                      | 12/40 [1:45:12<4:24:17, 566.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:12\t|\tTrain Loss: 1173.435\t|\tCosim score: 0.853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|█████████████████████████                                                    | 13/40 [1:55:12<4:19:27, 576.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:13\t|\tTrain Loss: 1173.355\t|\tCosim score: 0.853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|██████████████████████████▉                                                  | 14/40 [2:05:43<4:17:00, 593.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:14\t|\tTrain Loss: 1173.331\t|\tCosim score: 0.852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|████████████████████████████▉                                                | 15/40 [2:15:25<4:05:45, 589.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:15\t|\tTrain Loss: 1173.339\t|\tCosim score: 0.852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|██████████████████████████████▊                                              | 16/40 [2:24:44<3:52:08, 580.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:16\t|\tTrain Loss: 1173.365\t|\tCosim score: 0.851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████████████████████████████████▋                                            | 17/40 [2:33:59<3:39:37, 572.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:17\t|\tTrain Loss: 1173.399\t|\tCosim score: 0.851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|██████████████████████████████████▋                                          | 18/40 [2:43:11<3:27:42, 566.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:18\t|\tTrain Loss: 1173.438\t|\tCosim score: 0.851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Network error resolved after 0:00:27.948280, resuming normal operation.\n",
      " 48%|████████████████████████████████████▌                                        | 19/40 [2:52:46<3:19:11, 569.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:19\t|\tTrain Loss: 1173.478\t|\tCosim score: 0.850\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|██████████████████████████████████████▌                                      | 20/40 [3:02:05<3:08:40, 566.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:20\t|\tTrain Loss: 1173.517\t|\tCosim score: 0.850\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|████████████████████████████████████████▍                                    | 21/40 [3:11:20<2:58:13, 562.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:21\t|\tTrain Loss: 1173.551\t|\tCosim score: 0.850\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|██████████████████████████████████████████▎                                  | 22/40 [3:20:33<2:47:57, 559.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:22\t|\tTrain Loss: 1173.581\t|\tCosim score: 0.850\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|████████████████████████████████████████████▎                                | 23/40 [3:29:42<2:37:41, 556.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:23\t|\tTrain Loss: 1173.607\t|\tCosim score: 0.850\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████████████████████████████████████████████▏                              | 24/40 [3:39:03<2:28:47, 557.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:24\t|\tTrain Loss: 1173.630\t|\tCosim score: 0.849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|████████████████████████████████████████████████▏                            | 25/40 [3:48:22<2:19:32, 558.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:25\t|\tTrain Loss: 1173.650\t|\tCosim score: 0.849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████████████████████████████████████████████████                           | 26/40 [3:57:35<2:09:54, 556.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:26\t|\tTrain Loss: 1173.668\t|\tCosim score: 0.849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|███████████████████████████████████████████████████▉                         | 27/40 [4:06:16<1:58:17, 545.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:27\t|\tTrain Loss: 1173.683\t|\tCosim score: 0.849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|█████████████████████████████████████████████████████▉                       | 28/40 [4:14:56<1:47:37, 538.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:28\t|\tTrain Loss: 1173.696\t|\tCosim score: 0.849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████████████████████████████████████████████████████▊                     | 29/40 [4:23:36<1:37:37, 532.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:29\t|\tTrain Loss: 1173.710\t|\tCosim score: 0.849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|█████████████████████████████████████████████████████████▊                   | 30/40 [4:32:18<1:28:14, 529.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:30\t|\tTrain Loss: 1173.722\t|\tCosim score: 0.849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████████████████████████████████████████████████████████▋                 | 31/40 [4:40:58<1:19:01, 526.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:31\t|\tTrain Loss: 1173.735\t|\tCosim score: 0.849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|█████████████████████████████████████████████████████████████▌               | 32/40 [4:49:39<1:09:58, 524.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:32\t|\tTrain Loss: 1173.745\t|\tCosim score: 0.849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|███████████████████████████████████████████████████████████████▌             | 33/40 [4:58:19<1:01:03, 523.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:33\t|\tTrain Loss: 1173.756\t|\tCosim score: 0.849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|███████████████████████████████████████████████████████████████████▏           | 34/40 [5:06:59<52:15, 522.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:34\t|\tTrain Loss: 1173.767\t|\tCosim score: 0.849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|█████████████████████████████████████████████████████████████████████▏         | 35/40 [5:16:14<44:21, 532.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:35\t|\tTrain Loss: 1173.778\t|\tCosim score: 0.849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|███████████████████████████████████████████████████████████████████████        | 36/40 [5:25:26<35:53, 538.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:36\t|\tTrain Loss: 1173.789\t|\tCosim score: 0.849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████████████████████████████████████████████████████████████████████      | 37/40 [5:34:57<27:23, 547.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:37\t|\tTrain Loss: 1173.798\t|\tCosim score: 0.849\n"
     ]
    }
   ],
   "source": [
    "for x in word_lists:\n",
    "    wandb.init(project='Synthetic Net')\n",
    "    config = wandb.config\n",
    "    config.batch_size = 64\n",
    "    model = DenseNet(context_length = 10)\n",
    "    \n",
    "    training_files = [f'../processed_data/wiki_only/{y}_corpus_stopwords_c10.txt' for y in x]\n",
    "    training_data = load_training_batch(training_files,config.batch_size)\n",
    "    config.data = f'wiki_only_{x}'\n",
    "    \n",
    "\n",
    "    config.lr = 0.0005\n",
    "    config.momentum = 0.005\n",
    "    optimizer = optim.SGD(model.parameters(),lr=config.lr,momentum=config.momentum,weight_decay=0.01)\n",
    "    criterion = nn.L1Loss()\n",
    "\n",
    "    def cosim(v1,v2):\n",
    "        return np.dot(v1,v2)/(np.linalg.norm(v1)*np.linalg.norm(v2))\n",
    "\n",
    "    #scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, debug_set.shape[0], eta_min=config.lr)\n",
    "    #learning rate adjustment -- try 0.001\n",
    "\n",
    "    def train(model, iterator, optimizer, criterion):\n",
    "\n",
    "        epoch_loss = 0\n",
    "        epoch_acc = 0\n",
    "\n",
    "        model.train()\n",
    "        for batch in iterator:\n",
    "            optimizer.zero_grad()\n",
    "            features,labels = get_batch_embedding(batch,W_norm,vocab) \n",
    "        \n",
    "            feat = torch.Tensor(features).to(device)\n",
    "            label = torch.Tensor(labels).to(device)\n",
    "            predictions = model(feat).squeeze(1)\n",
    "            loss = criterion(predictions,label)      \n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "            cosim_score = np.mean([cosim(labels[i],predictions[i].cpu().detach().numpy()) for i in range(config.batch_size) ])\n",
    "\n",
    "        return epoch_loss,cosim_score\n",
    "\n",
    "    \n",
    "\n",
    "    config.epochs = 40\n",
    "\n",
    "    best_valid_loss = float('inf')\n",
    "\n",
    "    for epoch in tqdm(range(config.epochs)):   \n",
    "        train_loss,cosim_score= train(model.to(device),iter(training_data), optimizer, criterion)\n",
    "\n",
    "        #epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "        #if valid_loss < best_valid_loss:\n",
    "         #   best_valid_loss = valid_loss\n",
    "          #  torch.save(model.state_dict(), 'tut1-model.pt')\n",
    "\n",
    "        #print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "        wandb.log({\"loss\":train_loss,\"cosim_score\":cosim_score})\n",
    "        print(f'Epoch:{epoch+1:02}\\t|\\tTrain Loss: {train_loss:.3f}\\t|\\tCosim score: {cosim_score:.3f}')\n",
    "\n",
    "\n",
    "    torch.save(model.state_dict(),f'../outputs/{date.today().strftime(\"%Y-%m\")}_{config.data}_{wandb.run.name}.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e44d42-bfdc-4585-9711-8d52d2b596af",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Testing\n",
    "#Test 1 sentence\n",
    "#Test 1 batch\n",
    "#Test all \n",
    "\n",
    "random_sent = random.choice(training_data)[random.randint(0,config.batch_size-1)]\n",
    "y,x = random_sent.split(':')\n",
    "x = re.sub('[\\n\\r\\ ]+',' ',x).strip()\n",
    "sample_tensor = torch.Tensor([[get_glove_vec(word,W_norm,vocab) for word in x.split(' ')]])\n",
    "sample_output = model(sample_tensor)\n",
    "target_label = np.array(get_glove_vec(y,W_norm,vocab))\n",
    "\n",
    "output = sample_output.squeeze(1)\n",
    "vec_output = output.detach().numpy()\n",
    "print(vec_output.shape)\n",
    "\n",
    "def __distance(W, vocab, ivocab, vec_output):\n",
    "\n",
    "\n",
    "    dist = np.dot(W, vec_output.T).squeeze(1)\n",
    "    print(dist.shape)\n",
    "    a = np.argsort(-dist)[:10]\n",
    "\n",
    "    print(\"\\n                               Word       Unnormalized Cosine distance\\n\")\n",
    "    print(\"---------------------------------------------------------\\n\")\n",
    "    for i,x in enumerate(a):\n",
    "        print(\"%d%35s\\t\\t%f\" % (i,ivocab[str(x)], dist[x]))\n",
    "print(f\"Test 1 -- sample sentence: \\n\\n{random_sent}\\n\\n\")\n",
    "\n",
    "__distance(W_norm,vocab,ivocab,vec_output)\n",
    "\n",
    "\n",
    "print(f\"\\n\\n\\t\\tCosim score: {cosim(vec_output,target_label)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc79e2d1-7819-40f0-b542-3b91d946a77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_batch = random.choice(training_data)\n",
    "sample_batch_tensor = []\n",
    "target_batch_tensor = []\n",
    "for sentence in random_batch:\n",
    "    y,x = random_sent.split(':')\n",
    "    x = re.sub('[\\n\\r\\ ]+',' ',x).strip()\n",
    "    sample_tensor = [get_glove_vec(word,W_norm,vocab) for word in x.split(' ')]\n",
    "    target_batch_tensor.append(get_glove_vec(y,W_norm,vocab))\n",
    "    sample_batch_tensor.append(sample_tensor)\n",
    "    \n",
    "sample_batch_tensor = torch.Tensor(np.array(sample_batch_tensor))\n",
    "target_batch_tensor = np.array(target_batch_tensor)\n",
    "\n",
    "sample_output = model(sample_batch_tensor)\n",
    "\n",
    "output = torch.mean(sample_output,0)   #sum across embeddings\n",
    "vec_output = output.detach().numpy().reshape((1,100))\n",
    "\n",
    "print(f\"Test 2 -- sample batch: \\n\\n\")\n",
    "\n",
    "__distance(W_norm,vocab,ivocab,vec_output)\n",
    "\n",
    "\n",
    "print(f\"\\n\\n\\t\\tCosim score: {cosim(vec_output,target_label)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd3689d-d6c1-4a46-9c80-08bed61816ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Test 3: Custom\n",
    "\n",
    "##Testing\n",
    "#Test 1 sentence\n",
    "#Test 1 batch\n",
    "#Test all \n",
    "\n",
    "\n",
    "random_sent = 'pacific disaster response fund support armenian government fight spread covid year bank committed million loan electric networks armenia ensure electricity '\n",
    "target_word = 'pneumonia'\n",
    "target_label = np.array(get_glove_vec(target_word,W_norm,vocab))\n",
    "random_sent = re.sub('[\\n\\r\\ ]+',' ',random_sent).strip()\n",
    "\n",
    "sample_tensor = torch.Tensor([[get_glove_vec(word,W_norm,vocab) for word in random_sent.split(' ')]])\n",
    "sample_output = model(sample_tensor)\n",
    "output = sample_output.squeeze(1)\n",
    "vec_output = output.detach().numpy()\n",
    "print(f\"Test 3: Custom Test\\n\\n{random_sent}\\n\\n\")\n",
    "__distance(W_norm,vocab,ivocab,vec_output)\n",
    "print(f\"\\n\\n\\t\\tCosim score: {cosim(vec_output,target_label)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d3e5f8-2a5f-4da8-9c96-30a4eb537c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_tensor.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f4ec9a-1429-4caf-b3c2-01adc7a96a05",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
